{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textbook exercises\n",
    "16.3-2 Prove that a binary tree that is not full cannot correspond to an optimal prefix code.\n",
    "- The depth of a node in a tree will indicate how long its corresponding code is. Since the code for a node is determined by whether it is the left or right child of its ancestors - and the ancestors of their ancestors until the root - it will have the same length as the number of ancestors it has. Thus, an optimal prefix code that minimizes the length of all codes will have a tree of minimum depth. Unless a binary tree is full, it will not be the minimum depth tree of all possible trees of that size. \n",
    "\n",
    "16.3-3 What is an optimal Huffman code for the following set of frequencies, based on the first 8 Fibonacci numbers? {a:1 b:1 c:2 d:3 e:5 f:8 g:13 h:21} Can you generalize your answer to find the optimal code when the frequencies are the first n Fibonacci numbers?\n",
    "- {a:00000001 b:0000001 c:000001 d:00001 e:0001 f:001 g:01 h:1}.\n",
    "- The longest optimal code for Fib number n will be (n-1)*\"0\" + \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huffman encoding\n",
    "\n",
    "There is python code available at this gist, which will download the collected works of Shakespeare and, when complete, it will compress them using the Huffman compression algorithm.\n",
    "\n",
    "Implement encode so that it takes a dictionary which maps symbols to probabilities, and then produces the optimal Huffman encoding (i.e. it must return a new dictionary).\n",
    "Run the code and compress the complete works of Shakespeare. How big is the original file, what is the size of the compressed version? When the compressed version is decompressed is it identical to the original?\n",
    "\n",
    "Compress the complete works of Shakespeare using other compression methods and see what a poor job they do (eg. gzip, bzip2, zip). Bear in mind that we are using the optimal symbol code with frequencies constructed from the exact corpus that we are looking to compress, so nothing can beat us right?\n",
    "\n",
    "What is the percentage of 1’s in the compressed version and what is the percentage of 1’s in the uncompressed version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
