{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textbook exercises\n",
    "16.3-2 Prove that a binary tree that is not full cannot correspond to an optimal prefix code.\n",
    "- The depth of a node in a tree will indicate how long its corresponding code is. Since the code for a node is determined by whether it is the left or right child of its ancestors - and the ancestors of their ancestors until the root - it will have the same length as the number of ancestors it has. Thus, an optimal prefix code that minimizes the length of all codes will have a tree of minimum depth. Unless a binary tree is full, it will not be the minimum depth tree of all possible trees of that size. \n",
    "\n",
    "16.3-3 What is an optimal Huffman code for the following set of frequencies, based on the first 8 Fibonacci numbers? {a:1 b:1 c:2 d:3 e:5 f:8 g:13 h:21} Can you generalize your answer to find the optimal code when the frequencies are the first n Fibonacci numbers?\n",
    "- {a:00000001 b:0000001 c:000001 d:00001 e:0001 f:001 g:01 h:1}.\n",
    "- The longest optimal code for Fib number n will be (n-1)*\"0\" + \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huffman encoding\n",
    "\n",
    "There is python code available at this gist, which will download the collected works of Shakespeare and, when complete, it will compress them using the Huffman compression algorithm.\n",
    "\n",
    "Implement encode so that it takes a dictionary which maps symbols to probabilities, and then produces the optimal Huffman encoding (i.e. it must return a new dictionary).\n",
    "Run the code and compress the complete works of Shakespeare. How big is the original file, what is the size of the compressed version? When the compressed version is decompressed is it identical to the original?\n",
    "\n",
    "Compress the complete works of Shakespeare using other compression methods and see what a poor job they do (eg. gzip, bzip2, zip). Bear in mind that we are using the optimal symbol code with frequencies constructed from the exact corpus that we are looking to compress, so nothing can beat us right?\n",
    "\n",
    "What is the percentage of 1’s in the compressed version and what is the percentage of 1’s in the uncompressed version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "from urllib.request import urlopen\n",
    "import shutil\n",
    "import gzip\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from bitarray import bitarray\n",
    "import pickle\n",
    "from operator import itemgetter # to make dict sorted list of tuples\n",
    "\n",
    "# Download the file if need be:\n",
    "def download_file(url, filename):\n",
    "    if not os.path.exists(filename):\n",
    "        response = urlopen(url + filename)\n",
    "        shutil.copyfileobj(\n",
    "            gzip.GzipFile(fileobj=response), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "# build a frequency table:\n",
    "def build_freq(filename):\n",
    "    freq = defaultdict(int)\n",
    "    with open(filename, 'rb') as f:\n",
    "        for line in f:\n",
    "            for char in line:\n",
    "                freq[char] += 1\n",
    "    total = float(sum(freq.values()))\n",
    "    return {char: count / total for (char, count) in freq.items()}\n",
    "\n",
    "class Node():\n",
    "    def __init__(self,char='internal',freq=0):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.code = '0'\n",
    "    def __str__(self):\n",
    "        return(str(self.char))\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "    \n",
    "# insert to encoding tree \n",
    "def heap_push(array, key):\n",
    "    array.append(key)\n",
    "    array[0], array[-1] = array[-1], array[0]\n",
    "    min_heapify(array, 0)\n",
    "    \n",
    "# Huffman code\n",
    "def huffman_code(z):\n",
    "    if z.left != None:\n",
    "        z.left.code = bitarray(z.code + '0')\n",
    "        huffman_code(z.left)\n",
    "    if z.right != None:\n",
    "        z.right.code = bitarray(z.code + '1')\n",
    "        huffman_code(z.right)\n",
    "\n",
    "def inorder(root, dct):\n",
    "    if root != None:\n",
    "        inorder(root.left, dct)\n",
    "        if root.char != \"internal\":\n",
    "            dct[root.char] = root.code\n",
    "        inorder(root.right, dct)    \n",
    "\n",
    "# Now build the Huffman encoding:\n",
    "def encode(symb2freq):\n",
    "    \"\"\"Huffman encode the given dict mapping symbols to weights.\n",
    "    Accept a dictionary which maps a symbol to a probability.\n",
    "    Return a new dictionary which maps a symbol to a bitarray.\"\"\"\n",
    "    n = len(symb2freq)\n",
    "    Q = list([Node(*x) for x in symb2freq.items()]) # \n",
    "    heapq.heapify(Q)\n",
    "\n",
    "    for _ in range(n-1):\n",
    "        # make an internal node\n",
    "        z = Node()\n",
    "        # make the 2 min the children\n",
    "        z.left = heapq.heappop(Q)\n",
    "        z.right = heapq.heappop(Q)\n",
    "        z.freq = z.left.freq + z.right.freq\n",
    "        heapq.heappush(Q,z)\n",
    "        \n",
    "    root = heapq.heappop(Q)\n",
    "    huffman_code(root)\n",
    "    symb2code = {}\n",
    "    inorder(root, symb2code)\n",
    "    return(symb2code)\n",
    "\n",
    "# Now compress the file:\n",
    "def compress(filename, encoding, compressed_name=None):\n",
    "    if compressed_name is None:\n",
    "        compressed_name = filename + \".huff\"\n",
    "    output = bitarray()\n",
    "    with open(filename, 'rb') as f:\n",
    "        for line in f:\n",
    "            for char in line:\n",
    "                output.extend(encoding[char])\n",
    "    N = len(output)\n",
    "    with open(compressed_name, 'wb') as f:\n",
    "        pickle.dump(N, f)\n",
    "        pickle.dump(encoding, f)\n",
    "        output.tofile(f)\n",
    "\n",
    "\n",
    "# Now decompress the file:\n",
    "def decompress(filename, decompressed_name=None):\n",
    "    if decompressed_name is None:\n",
    "        decompressed_name = filename + \".dehuff\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        N = pickle.load(f)\n",
    "        encoding = pickle.load(f)\n",
    "        bits = bitarray()\n",
    "        bits.fromfile(f)\n",
    "        bits = bits[:N]\n",
    "\n",
    "    # Totally cheating here and using a builtin method:\n",
    "    output = bits.decode(encoding)\n",
    "    with open(decompressed_name, 'wb') as f:\n",
    "        f.write(bytes(output))\n",
    "\n",
    "\n",
    "url = \"http://www.gutenberg.org/ebooks/\"\n",
    "filename = \"100.txt.utf-8\"\n",
    "\n",
    "download_file(url, filename)\n",
    "freq = build_freq(filename)\n",
    "encoding = encode(freq)\n",
    "compress(filename, encoding)\n",
    "decompress(filename + \".huff\")\n",
    "\n",
    "# Do you get identical files?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
